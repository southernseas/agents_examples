{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# If you get a Name Error - head over to Python Foundations guide (guide 6)\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n",
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "#\n",
    "#  The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "from pyexpat import model   \n",
    "\n",
    "\n",
    "response=openai.chat.completions.create(model=\"gpt-4.1-nano\", messages=messages)\n",
    "answer=response.choices[0].message.content\n",
    "print(answer)                            \n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If 5 machines take 5 minutes to make 5 widgets, how long would 100 machines take to make 100 widgets?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the problem step-by-step:\n",
      "\n",
      "- **Given:** 5 machines take 5 minutes to make 5 widgets.\n",
      "  \n",
      "This means:\n",
      "\n",
      "- Each machine takes 5 minutes to make 1 widget (since 5 machines make 5 widgets in 5 minutes, so each machine is responsible for 1 widget in that time).\n",
      "\n",
      "Now, the question is: **How long would 100 machines take to make 100 widgets?**\n",
      "\n",
      "- Since each machine makes 1 widget in 5 minutes, then 100 machines can make 100 widgets in the **same 5 minutes** (because each machine works independently).\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "\\[\n",
      "\\boxed{5 \\text{ minutes}}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "2 + 2 equals 4."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry: Healthcare diagnostics AI\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Painpoint: A significant business pain point in healthcare diagnostics that agentic AI could address is **reducing diagnostic errors and delays caused by limited integration and scalability of existing AI tools**.\n",
       "\n",
       "### Explanation:\n",
       "- **Context:** Healthcare diagnostics increasingly relies on AI to interpret medical images, lab results, and patient data. However, many AI systems are narrowly specialized, require manual configuration, and lack the ability to autonomously adapt, collaborate, and integrate multiple data sources dynamically.\n",
       "  \n",
       "- **Pain Point:**  \n",
       "  - Diagnostic errors or delays often arise because current AI tools operate in silos and depend heavily on human experts to orchestrate analyses.\n",
       "  - Radiologists and pathologists face overwhelming workloads, and manual validation slows turnaround times.\n",
       "  - Fragmented AI applications can’t autonomously synthesize complex patient data from different modalities (imaging, genomics, EHRs) in a clinically meaningful way.\n",
       "\n",
       "- **Value of Agentic AI:**  \n",
       "  - Agentic AI — autonomous, goal-driven AI agents — could act as intelligent coordinators that proactively gather, integrate, and interpret diverse diagnostic data.\n",
       "  - They can identify conflicting or uncertain findings, request additional inputs or tests, and present consolidated, prioritized reports to clinicians.\n",
       "  - This reduces cognitive overload on human practitioners, cuts diagnostic delays, lowers error rates, and improves patient outcomes.\n",
       "  - Additionally, agentic AI can continuously learn from new data and adjust diagnostic strategies, ensuring scalability and adaptability across diverse clinical environments.\n",
       "\n",
       "### In summary:\n",
       "**Business pain point:** Diagnostic inefficiencies and errors due to fragmented, non-autonomous AI tools and data silos.\n",
       "\n",
       "**Worth solving for agentic AI:** Developing autonomous AI agents that integrate multi-source clinical data, reduce diagnostic errors/delays, and support clinicians in delivering faster, more accurate diagnoses at scale. This could provide compelling ROI by improving care quality, reducing costs from misdiagnosis, and enabling better resource allocation in healthcare systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Solution: A significant business pain point in Healthcare Diagnostics AI that agentic AI could help solve is **“Reducing diagnostic errors and improving decision support in complex cases.”**\n",
       "\n",
       "### Why this pain point?\n",
       "- **Diagnostic errors** are a major issue in healthcare, leading to misdiagnosis, delayed treatment, increased costs, and poor patient outcomes.\n",
       "- Traditional AI models often provide static predictions without context-aware reasoning or the ability to autonomously gather additional relevant data.\n",
       "- Clinicians face information overload and complexity, needing tools that can proactively assist by integrating diverse data sources, flagging anomalies, and reasoning about uncertain evidence.\n",
       "\n",
       "### How Agentic AI can address this pain point:\n",
       "- **Autonomous data integration:** Agentic AI can proactively pull in relevant patient history, lab results, imaging, and even literature or clinical guidelines without manual prompting.\n",
       "- **Contextual reasoning:** It can reason through ambiguous or conflicting data points, identifying patterns or rare conditions that standard algorithms might miss.\n",
       "- **Interactive collaboration:** Acting as an intelligent assistant, it can engage clinicians with clarifying questions or suggest next-best-action tests dynamically.\n",
       "- **Continuous learning:** It can update its models and reasoning pathways based on new data and outcomes autonomously.\n",
       "\n",
       "### Business benefits:\n",
       "- Reduces costly diagnostic errors and associated malpractice claims.\n",
       "- Improves patient outcomes and satisfaction by providing more accurate, timely diagnoses.\n",
       "- Lowers clinician workload and cognitive burden, enhancing productivity.\n",
       "- Supports regulatory compliance by providing transparent, explainable decision processes.\n",
       "\n",
       "In summary, developing agentic AI solutions that autonomously augment and enhance diagnostic decision-making in complex cases is a highly valuable business opportunity in healthcare diagnostics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First create the messages:\n",
    "\n",
    "messages1 = [{\"role\": \"user\", \"content\": \"What is a industry name that might be worth solving for agentic ai. Limit Respone to  in 30 characters - do not print other text\"}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages1\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(\"Industry: \" +   answer)\n",
    "\n",
    "messages2 = [{\"role\": \"user\", \"content\": \"What is a business pain point that might be worth solving for agentic ai in industry \" + answer}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages2\n",
    ")\n",
    "\n",
    "answer2 = response.choices[0].message.content\n",
    "# print(answer)\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"Painpoint: \" +    answer2))\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = answer2\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message\n",
    "\n",
    "messages3 = [{\"role\": \"user\", \"content\": \"What is a solution for  \" + answer2}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages2\n",
    ")\n",
    "\n",
    "answer3 = response.choices[0].message.content\n",
    "# print(answer)\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"Solution: \" + answer3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
